#cloud-config
ssh_authorized_keys:
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC8yXjMX812gbdUsosLvIA/zPrRZI+iOKo8Igq7eiwRTeJKxIkRd2vxDGDfqzCnMhUPPgLW7YM0FWt1u8ZTlXyL4fv1KZuYMRF+27GuU2b/IKu4JYlHDDHrvKCr9tyKb+YVPrAfzi2xVRTGGZG6GRmAiDw8HSUFdejuDLIropAFQu9gAow9aiuQG6kmxZK8qdwIu03eZhuUHCRySCPbusjO+I2JEyVa7lM+P1zt2znDwXsdGjTzHE7NSu5z/VHzho3STWolBm5Vk8uLNYKhjs0eiw/FXV5t+c08Y3JA1LwjAmfOBS23ERSHMG8I3EVSnB9utrdLXejwFAV/jY+Dl2QX9o8brFePBe26MbSg9udD0yfrVz4HEG6NigK6sSx97Zs0lcaSwvjJsnp/J3B1IQMlNRLJGQ7WxM9H2rtoMmD7/iPdADevehEui8C9iaADk6j8AWtN0SJbccSvidrFXW7eH/YSYW394rk8Cl1xBk2RORv3OGVy/RNVt6/Pk/BzvqKf3RvKlbvbFZsWeBSZHDAKeer7001g8HmKV7c8fnDsxIU9Ro3aeWpsX1rQ/jzH1an2deXzVDX1Xbm80VmL5M53dr4w2ZiF5uEIODEUr2nssvl6fhdnaXmbO0vsIyOVawl8mkQ7CBsW06Q+kNs7iDvwVmoG/DD0k4i86La2TBpGvQ== andre.hartmann@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAt8djQXfn5U7H85oDzuZRfRONF+jVqn3Mp9t3tnBrJdKyTccfDovq1sekzEdOFdmj74yfS8bzaIO9pDUczy6j5k2MtDCoRnzAO6KZc46jMJ2GjhLArUuHLjmAw2r9LotZ30LEIEvJdmUI7mDlPMczv381PghyM8+DsYv62UrfjDiOsZ4EVkYnztQlO3ntNE16RFNj4fbfErQz67kmw0lB8C6bAf0RuRmvXzB7xRMplmknQnLusoURmySKdZM0GUe0VY6fmqOsgzHVLoEs1m82V8QK1ac/1DSHA91v50MbpCjTVLaRhjR8nmhWBedlhb6j5ClZdAQ8iwyyWC1MFQuvKw== henning@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIgO42Rr98DRo4N86Uk4cqHcnbA0iPhL7/DQXRNs+o2vfnfoTVNQiyfq8XzScb+pRJpiq2wW2OthMVRUJsiO4PECw7avYAi0M8cyCsu+ZUoIeMlu+TssWA00GZgdKcQKyCoyLlGbPu2z4GpM9tX+7ASMbMuk6fpm6n9af1YbTm2eqKKXpHDJO+aex3WCj1VyQpCgCD4zquGRy8JRSiQ+QGyGZHIzWWpo3Lc1xGqSQu6L3h4RMrwtZNOjMr/xxxnApOQjBLr70Q8MlYnAhXrIyLjNOaMabMKVxDEltrvN2rCWfN/DFyRi4c5GiDKk1/lwlfO9dRieUqXm9J670PWhwx jan.mussler@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOjGGBqrWGdbh0yfkBRE04IbdiAP2TJ2RXnfnp3OV8Lw+jg7cUqeZA5l2vIhFd2ctKPd5OGE3K/A6xCK3hFV9V01oYbH8S3IvrhyA+VjBG0d/ZgTm6GCrlE4XeAt9/ourBSxrrE04lfO786dhLsGEOa5WvvSG3Z/6BhyC/1e5Bd37nnWB363fjAsbg1UgSPr99QZQ5l2mSxN4i2IpJjULBWpLvrJLLJzzl67aaVhDjdtggEU+pMsOoRpDuJ46cYMMDvBI9gyyal2G1aIkqu9iejt1bly53Th2ZAiXecXxEh4K3a5H/Czf70vpCzXQiG1OuZRD1PaSpqw4+zzcizZdX matthias@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCs4NhH7uwlnklYYlV1GP57XX9NHYgXNv0njfEVowR1jFSKiMdEUtPKz5lOAeDtKpck9HyjxVOTSutNOIBZkkgN/FgkcpNbc59nIO4ELUzipkJivuYNO1lDAjCQi1qwYo+uksiNfcsao9mn7nd9Rh1g8TXYv95TSvml9v/Dolmanm1qj6OkbDw1xIurnNsoCjdxCWwSRGNja4r+PQc8pi+1xpdUBEvn40CeBdU7b/hZnv/BM9FIKSsVlIwMR2i/Co2rxCKo9B3q4dmdQ/2C1QczINVpPQcNUMuiljJFMXvT7dgfNsnUBe8vFuoPgqohJ/m8AiKZZOyoRNiCuELnKLRKqxosDmJz47Y0YiYgZk9jpnmt+x1fwqhY2R85F7W4RybpX3AFL1jOqOT2lE+idkhyeFq/pPoAiPvUcpQSmL9AwlrG6cPklTJZW+dUzH/W6kNlgl/T6hnMn4Mu+IljG08Iyb/HBdmOX+uRq5wdF8lI9Zjzlwg+j7HMa3p1O7MNwpSJVjVXkhUXH0WrFrK2JkwgXokIWvu0o+lajYOmXRQeGCyVybg06WFCzOXnK2toVucFMuAGoM0NkthAnodZCk+xXLNrtHOYagpdJ/x/Q88vuDsZr7IG0NvgX/OCq1a5lpnIydCe+tABNNKcRaOuOLbDYVgUaeVzIXyJjRYu5ZN/JQ== mikkel.larsen@zalando.de'
  - 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIISHc8p8+ycB9H6SI/i3Uu/OI5G3vYNsZTn0DffPvfOA martin.linkhorst@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDf3X7MZjYRZD2mI7dvW+c/8dUeDrdqAKZD/C9r+aGa6hWzbGeUZ7cub8to6X9Cl5p3MsTdtFV/OIHRIvxoIGYkz3CRHEBtUdUwOjF9lpBoB/yRMJyxlogmMCm9KGSUM4K+xgIX6qBHq/UeY2Yqumec5lhuLk+7wTmXYQM3+fvvHB8MY//UEadvjuDdotNGQ4jxkJjfoTQj6dspvsZCJ4kIIef9DLSJQ4oCV7sDCVDWPllb3ni9WJYD4vTguI82DI0moQV0WIPplH6rrK+ctVmPyix/IertpqWbiLgmdz3SAyGW45uws2ozGB1S+tZJF+RcNFbbAimoz6QHT+kgL1qmpxa7yba7y3m5pUHqGdhLb+X4Xe3oMZGk7cwBOECw8JUzxzqQKxpF1PfbH8wJ8AiKF7Xr/KJNk9Axsm1zV0DDWv3Z2oK7m8pNiq3mlhv6ovIpXsTq40uaasuLSfmLjSagQDT6ufBAUbaSAJfM0VFo4diIOCDnXH0SX1T8X3EPKbyDg0l/y0pE+FxXQvBK2rzgeynoK5NrvGl1xhJGetbMsl0+WtnIr/PbIQDTo9UQAzOWnHsTs72VqNbeJN4w8ksTqNhXiQO6zlhWqoPL/BeXvRc4N0R8iq9vIstjtuAZkaFsm5TH7Uzz3WTHzKbJ0/5+sefX4cucb/QjImvcVV1UEw== nick.juettner@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCuFg0sZtpORWFESaGFnDHYPDG2mYAEsg3pz2yvLn8L2U4b+clIqzQyMjjnze/syB979hVxAucb5A7YR8s7jPIcHUsTcLdGJUNATxiYSdReFj+6ki+6vk01zf9fTVrmAy39SYMi0hSicyMpQL7ur1osnqZ/OEq7+m/qJD6dQ5KpSMVr72kcdXqObEGxIKwPSJlyZ2df1UoMxuslLeGzovuNfngFMTpE7K6A1Nuysn0Vm4EIJ1/UC1nADbTsRexpwCD/7ZanS349RGhGA7SLeXKwSEejL6IkaMF6mWyy4+IWeKraSogw73oM9Quyzq72AwZos4WTb61DVWcRaRXj0D1/ raffaele.di.fazio@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCq3oEP8qhMvGtlR1bgVc9tFOVJ5B5RMKtm6UQ/zXQUpm8DQ04SxdM2U7TfuLien2HSfpHAlYe0eLJZUfIqCXUeZ37v0ozj2RglireEcJm0t9XJ7kTS4kqVxrL6iuN6qQVGHs0vxoo/o9+SP0YkuuJoXwJvVI4yKVbnbfA5hKaAffAYPmfgqOZ7+3AMwmaj/D3tI0xVEA48ptGkj5nnOl0pXlfLRNvbnXOCa/dTKUgkma1F0lXoTipkRspsMEiAnwfJ1dwnzgNzllt//Ao/H+yOVR8fWJ7d+nowszIk6zwUR7c6walxKKf5Oy5bQBU49MZ6xLP1oma9F2+llmV7qpqx rodrigo.reis@zalando.de'
  - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCqAikaHsZWMuJvKZphZPZG0fnKMvVCRfBAbIS6e0Y+YqM0PfsWgB5e4f5TrbisQHdKopbfZVwYIaV/NegEuinrYPKC7t2ese/HjxgjHR95zHOcDP19Cbo+xeyH8zbRd9K3iRSyCUSMNRw5NL6zN8JOSl12m8QWQA4hTjFTmt870fIT4RLxu9qGlbQipUm57E/SotsNC41MQ/PsLQzOAviKrkS1rei2vzRHzAcjz1Z7GT5oH+dFVUC66kKa0XWDvq+VtkRVoLvS2chrIPCgESeeZAyOKyiOoyJxFFFiMVK48MWDBBIYTIsHE0qs/RwBi9+8lQGiHK5Rpk2djcloO0c7 sandor.szuecs@zalando.de'
  - 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINkh52Py+FvH9CRLDQg0gzvjEIrzwA45yMTXTsl2BVxV alexey.ermakov@zalando.de'
coreos:
  update:
    reboot-strategy: "off"
  units:
    - name: etcd-member.service
      command: start
      enable: true
      content: |
        [Unit]
        Wants=network.target
        [Service]
        Type=simple
        Restart=on-failure
        RestartSec=10s
        ExecStartPre=/usr/bin/mkdir --parents /var/lib/coreos
        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/lib/coreos/etcd-member-wrapper.uuid
        ExecStart=/usr/bin/rkt run --uuid-file-save=/var/lib/coreos/etcd-member-wrapper.uuid --port=2379-tcp:2379 --mount volume=dns,target=/etc/resolv.conf --volume dns,kind=host,source=/run/systemd/resolve/resolv.conf,readOnly=true --insecure-options=image docker://registry.opensource.zalan.do/teapot/etcd-proxy:master-1 -- {{ETCD_ENDPOINTS}}
        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/lib/coreos/etcd-member-wrapper.uuid
        [Install]
        WantedBy=multi-user.target

    - name: docker.service
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
            [Service]
            EnvironmentFile=/etc/kubernetes/cni/docker_opts_cni.env
        - name: 50-downgrade.conf
          content: |
            [Unit]
            Requires=docker-downgrade.service
            After=docker-downgrade.service
        - name: 60-dockeropts.conf
          content: |
            [Service]
            Environment="DOCKER_OPTS=--log-opt=max-file=2 --log-opt=max-size=50m"
            Environment=DOCKER_SELINUX=

    - name: flanneld.service
      drop-ins:
      - name: 20-version.conf
        content: |
          [Service]
          Environment="FLANNELD_IFACE="$private_ipv4"
          Environment="FLANNELD_ETCD_ENDPOINTS="http://127.0.0.1:2379"
          Environment="FLANNEL_IMAGE_TAG=v0.9.1"
          Environment="FLANNEL_OPTS=--ip-masq=true -v 2"

    - name: flannel-docker-opts.service
      drop-ins:
      - name: 20-version.conf
        content: |
          [Service]
          Environment="FLANNEL_IMAGE_TAG=v0.9.1"

    - name: timesynced-enable-network-time.service
      command: start
      runtime: true
      content: |
        [Service]
        Type=oneshot
        ExecStart=/usr/bin/timedatectl set-ntp true

        [Install]
        WantedBy=multi-user.target

    - name: kube2iam-iptables.service
      command: start
      runtime: true
      content: |
        [Service]
        Type=oneshot
        ExecStart=/usr/sbin/iptables \
          --append PREROUTING \
          --protocol tcp \
          --destination 169.254.169.254 \
          --dport 80 \
          --in-interface cni0 \
          --match tcp \
          --jump DNAT \
          --table nat \
          --to-destination $private_ipv4:8181

        [Install]
        WantedBy=multi-user.target

    - name: docker-downgrade.service
      content: |
        [Service]
        Type=oneshot
        ExecStart=/opt/bin/downgrade-docker

        [Install]
        WantedBy=multi-user.target

    - name: dockercfg.service
      command: start
      runtime: true
      content: |
        [Service]
        Type=oneshot
        ExecStartPre=/usr/bin/mkdir -p /root/.docker
        ExecStart=/opt/bin/dockercfg.sh

        [Install]
        WantedBy=multi-user.target

    - name: kubelet.service
      command: start
      runtime: true
      content: |
        [Service]
        Environment=KUBELET_IMAGE_TAG=v1.8.5_coreos.0
        Environment=KUBELET_IMAGE_URL=docker://registry.opensource.zalan.do/teapot/hyperkube
        Environment="RKT_RUN_ARGS=--insecure-options=image \
        --uuid-file-save=/var/run/kubelet-pod.uuid \
        --volume dns,kind=host,source=/etc/resolv.conf \
        --mount volume=dns,target=/etc/resolv.conf \
        --volume hosts,kind=host,source=/etc/hosts \
        --mount volume=hosts,target=/etc/hosts \
        --volume var-log,kind=host,source=/var/log \
        --mount volume=var-log,target=/var/log \
        --volume var-lib-cni,kind=host,source=/var/lib/cni \
        --mount volume=var-lib-cni,target=/var/lib/cni \
        --volume dockercfg,kind=host,source=/root/.docker/config.json \
        --mount volume=dockercfg,target=/root/.docker/config.json \
        --set-env=HOME=/root"
        ExecStartPre=/usr/bin/mkdir -p /var/log/containers
        ExecStartPre=/bin/mkdir -p /var/lib/cni
        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
        --cni-conf-dir=/etc/kubernetes/cni/net.d \
        --network-plugin=cni \
        --container-runtime=docker \
        --rkt-path=/usr/bin/rkt \
        --register-node \
        --allow-privileged \
        --node-labels=kubernetes.io/role=worker \
        --node-labels=flannel=local \
        --node-labels={{NODE_LABELS}} \
        --cluster-dns=10.3.0.10 \
        --cluster-domain=cluster.local \
        --kubeconfig=/etc/kubernetes/kubeconfig \
        --require-kubeconfig \
        --healthz-bind-address=0.0.0.0 \
        --healthz-port=10248 \
        --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
        --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem \
        --cloud-provider=aws \
        --feature-gates=ExperimentalCriticalPodAnnotation=true,TaintBasedEvictions=true \
        --system-reserved=cpu=100m,memory=164Mi \
        --kube-reserved=cpu=100m,memory=282Mi
        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target

    - name: kube-node-drainer.service
      enable: true
      command: start
      runtime: true
      content: |
        [Unit]
        Description=drain this k8s node to make running pods time to gracefully shut down before stopping kubelet
        After=docker.service

        [Service]
        Type=oneshot
        RemainAfterExit=true
        ExecStart=/bin/true
        TimeoutStopSec=120s
        ExecStop=/bin/sh -c '/usr/bin/rkt run --insecure-options=image \
          --volume=kube,kind=host,source=/etc/kubernetes,readOnly=true \
          --mount=volume=kube,target=/etc/kubernetes \
          --net=host \
          docker://registry.opensource.zalan.do/teapot/hyperkube:v1.8.5_coreos.0 \
          --exec=/kubectl -- \
            --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
            label node $(hostname) \
            lifecycle-status=draining \
            --overwrite; /usr/bin/rkt run --insecure-options=image \
          --volume=kube,kind=host,source=/etc/kubernetes,readOnly=true \
          --mount=volume=kube,target=/etc/kubernetes \
          --net=host \
          docker://registry.opensource.zalan.do/teapot/hyperkube:v1.8.5_coreos.0 \
          --exec=/kubectl -- \
            --kubeconfig=/etc/kubernetes/kubeconfig \
            drain $(hostname) \
            --ignore-daemonsets \
            --delete-local-data \
            --force'

        [Install]
        WantedBy=multi-user.target

write_files:

  - path: /etc/kubernetes/cni/docker_opts_cni.env
    content: |
      DOCKER_OPT_BIP=""
      DOCKER_OPT_IPMASQ=""

  - path: /etc/kubernetes/ssl/worker.pem
    encoding: gzip+base64
    content: {{WORKER_CERT}}

  - path: /etc/kubernetes/ssl/worker-key.pem
    encoding: gzip+base64
    content: {{WORKER_KEY}}

  - path: /etc/kubernetes/ssl/ca.pem
    encoding: gzip+base64
    content: {{CA_CERT}}

  - path: /etc/kubernetes/kubeconfig
    content: |
        apiVersion: v1
        kind: Config
        clusters:
        - name: local
          cluster:
            server: {{API_SERVER}}
        users:
        - name: kubelet
          user:
            token: {{WORKER_SHARED_SECRET}}
        contexts:
        - context:
            cluster: local
            user: kubelet
          name: kubelet-context
        current-context: kubelet-context

  - path: /etc/kubernetes/cni/net.d/10-flannel.conf
    content: |
        {
            "name": "podnet",
            "type": "flannel",
            "delegate": {
                "isDefaultGateway": true
            }
        }

  - path: /opt/bin/dockercfg.sh
    owner: root:root
    permissions: 0755
    content: |
      #!/bin/bash
      iid="instance-identity-document:$(curl http://169.254.169.254/latest/dynamic/instance-identity/pkcs7)"
      iid="$(echo -n "$iid" | base64 -w 0)"
      cat << EOF > /root/.docker/config.json
      {
        "auths": {
          "https://pierone.stups.zalan.do": {
            "auth": "${iid}"
          }
        }
      }
      EOF

  - path: /opt/bin/downgrade-docker
    owner: root
    permissions: 0755
    content: |
      #!/bin/bash
      set -euo pipefail
      if [[ ! -f "/etc/coreos/docker-1.12" ]]; then
        echo -n "yes" > /etc/coreos/docker-1.12
        echo "Rebooting to downgrade Docker"
        reboot
        exit 1
      fi

  - path: /home/core/.toolboxrc
    owner: core
    content: |
      TOOLBOX_DOCKER_IMAGE=registry.opensource.zalan.do/teapot/microscope
      TOOLBOX_DOCKER_TAG=v0.0.4

  - path: /root/.toolboxrc
    owner: root
    content: |
      TOOLBOX_DOCKER_IMAGE=registry.opensource.zalan.do/teapot/microscope
      TOOLBOX_DOCKER_TAG=v0.0.4

  - path: /etc/systemd/timesynced.conf
    owner: root
    content: |
      [Time]
      NTP=0.amazon.pool.ntp.org 1.amazon.pool.ntp.org 2.amazon.pool.ntp.org 3.amazon.pool.ntp.org

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-cluster-autoscaler
  namespace: kube-system
  labels:
    application: kube-cluster-autoscaler
spec:
  selector:
    matchLabels:
      application: kube-cluster-autoscaler
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        application: kube-cluster-autoscaler
      annotations:
        logging/destination: "{{.Cluster.ConfigItems.log_destination_infra}}"
        prometheus.io/path: /metrics
        prometheus.io/port: "8085"
        prometheus.io/scrape: "true"
    spec:
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      serviceAccountName: cluster-autoscaler
      dnsPolicy: Default
      tolerations:
      - key: node.kubernetes.io/role
        value: master
        effect: NoSchedule
      containers:
      - name: cluster-autoscaler
{{- if eq .Cluster.ConfigItems.experimental_cluster_autoscaler_check_scaling_events "true" }}
        image: registry.opensource.zalan.do/teapot/kube-cluster-autoscaler:v1.18.2-internal.29
{{- else }}
        image: registry.opensource.zalan.do/teapot/kube-cluster-autoscaler:v1.18.2-internal.27
{{- end }}
        command:
          - ./cluster-autoscaler
          - --v=1
          - --stderrthreshold=info
          - --scale-down-utilization-threshold={{.Cluster.ConfigItems.autoscaling_utilization_threshold}}
          - --cloud-provider=aws
          - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,zalando.de/cluster-local-id/{{ .LocalID }}
          - --expendable-pods-priority-cutoff=-1000000
          - --skip-nodes-with-system-pods=false
          - --skip-nodes-with-local-storage=false
          - --scale-up-cloud-provider-template=true
          - --expander=highest-priority
          - --balance-similar-node-groups
          - --max-node-provision-time=7m
          - --max-nodes-total={{ nodeCIDRMaxNodes (parseInt64 .Cluster.ConfigItems.node_cidr_mask_size) (parseInt64 .Cluster.ConfigItems.reserved_nodes) }}
          - --scale-down-enabled={{ .Cluster.ConfigItems.autoscaling_scale_down_enabled }}
          - --max-empty-bulk-delete={{ .Cluster.ConfigItems.autoscaling_max_empty_bulk_delete }}
          - --scale-down-unneeded-time={{ .Cluster.ConfigItems.autoscaling_scale_down_unneeded_time }}
          - --scale-down-delay-after-add=-1s
          - --backoff-no-full-scale-down=true
          - --max-pod-eviction-time={{ .Cluster.ConfigItems.cluster_autoscaler_max_pod_eviction_time }}
          - --topology-spread-constraint-scale-factor=3
          - --disable-node-instances-cache=true
          - --scale-down-ignore-schedulable-pods=true
          - --unremovable-node-recheck-timeout={{.Cluster.ConfigItems.autoscaling_unremovable_node_recheck_timeout}}
        resources:
          requests:
            cpu: {{.Cluster.ConfigItems.cluster_autoscaler_cpu}}
            memory: {{.Cluster.ConfigItems.cluster_autoscaler_memory}}
        env:
          - name: AWS_REGION
            value: {{ .Region }}
          - name: KUBE_MAX_PD_VOLS
            value: "26"
      nodeSelector:
        node.kubernetes.io/role: master

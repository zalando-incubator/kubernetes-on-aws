apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-cluster-autoscaler
  namespace: kube-system
  labels:
    application: kubernetes
    component: kube-cluster-autoscaler
spec:
  selector:
    matchLabels:
      daemonset: kube-cluster-autoscaler
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        application: kubernetes
        component: kube-cluster-autoscaler
        daemonset: kube-cluster-autoscaler
      annotations:
        logging/destination: "{{.Cluster.ConfigItems.log_destination_infra}}"
        prometheus.io/path: /metrics
        prometheus.io/port: "8085"
        prometheus.io/scrape: "true"
    spec:
      dnsConfig:
        options:
          - name: ndots
            value: "1"
      serviceAccountName: cluster-autoscaler
      dnsPolicy: Default
      tolerations:
      - key: node.kubernetes.io/role
        value: master
        effect: NoSchedule
      containers:
      - name: cluster-autoscaler
        image: container-registry.zalando.net/teapot/kube-cluster-autoscaler:v1.18.2-internal.43
        command:
          - ./cluster-autoscaler
          - --v={{.Cluster.ConfigItems.autoscaling_autoscaler_log_level}}
          - --stderrthreshold=info
          - --scale-down-utilization-threshold={{.Cluster.ConfigItems.autoscaling_utilization_threshold}}
          - --cloud-provider=aws
          - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,zalando.de/cluster-local-id/{{ .LocalID }}
          - --expendable-pods-priority-cutoff=-1000000
          - --skip-nodes-with-system-pods=false
          - --skip-nodes-with-local-storage=false
          - --scale-up-cloud-provider-template=true
          - --expander=highest-priority
          - --balance-similar-node-groups
          - --max-node-provision-time=7m
          {{ $pod_cidr_size := "15" }}
          - --max-nodes-total={{ nodeCIDRMaxNodesPodCIDR (parseInt64 $pod_cidr_size) (parseInt64 .Cluster.ConfigItems.node_cidr_mask_size) (parseInt64 .Cluster.ConfigItems.reserved_nodes) }}
          - --scale-down-enabled={{ .Cluster.ConfigItems.autoscaling_scale_down_enabled }}
          - --max-empty-bulk-delete={{ .Cluster.ConfigItems.autoscaling_max_empty_bulk_delete }}
          - --scale-down-unneeded-time={{ .Cluster.ConfigItems.autoscaling_scale_down_unneeded_time }}
          - --scale-down-delay-after-add=-1s
          - --backoff-no-full-scale-down=true
          - --max-pod-eviction-time={{ .Cluster.ConfigItems.cluster_autoscaler_max_pod_eviction_time }}
          - --max-graceful-termination-sec={{ .Cluster.ConfigItems.cluster_autoscaler_max_graceful_termination_sec }}
          - --disable-node-instances-cache=true
          - --scale-down-ignore-schedulable-pods=true
          - --unremovable-node-recheck-timeout={{.Cluster.ConfigItems.autoscaling_unremovable_node_recheck_timeout}}
          - --max-unschedulable-pods-considered={{.Cluster.ConfigItems.cluster_autoscaler_max_usnchedulable_pods_considered}}
        resources:
          requests:
            cpu: {{.Cluster.ConfigItems.cluster_autoscaler_cpu}}
            memory: {{.Cluster.ConfigItems.cluster_autoscaler_memory}}
        env:
          - name: AWS_REGION
            value: {{ .Region }}
      nodeSelector:
        node.kubernetes.io/role: master

#cloud-config
write_files:
  - owner: root:root
    path: /etc/kubernetes/secrets.env
    content: |
      NODEPOOL_TAINTS=node.kubernetes.io/role=master:NoSchedule{{if index .NodePool.ConfigItems "taints"}},{{.NodePool.ConfigItems.taints}}{{end}}
      NODE_LABELS=master=true,node.kubernetes.io/exclude-from-external-load-balancers,node.kubernetes.io/distro=ubuntu,cluster-lifecycle-controller.zalan.do/decommission-priority=999,{{ .Values.node_labels }}{{if index .NodePool.ConfigItems "labels"}},{{.NodePool.ConfigItems.labels}}{{end}}{{if eq .Cluster.ConfigItems.control_plane_asg_lifecycle_hook "true" }},asg-lifecycle-hook=true{{end}}
      NODEPOOL_NAME={{ .NodePool.Name }}
      KUBELET_ROLE=master

  - owner: root:root
    path: /etc/kuberuntu/s3-certs.env
    content: |
      S3_CERTS_BUCKET={{ .S3GeneratedFilesPath }}
      AWS_DEFAULT_REGION={{ .Cluster.Region }}

  - owner: root:root
    path: /etc/kubernetes/config/kubelet.yaml
    content: |
      # https://github.com/kubernetes/kubernetes/blob/v1.13.6/staging/src/k8s.io/kubelet/config/v1beta1/types.go
      apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      staticPodPath: "/etc/kubernetes/manifests"
      clusterDomain: cluster.local
{{- if not (index .Cluster.ConfigItems "enable_cfs_quota") }}
      cpuCFSQuota: false
{{- end }}
      featureGates:
        CSIMigration: {{ .Cluster.ConfigItems.enable_csi_migration }}
{{- if eq .Cluster.ConfigItems.enable_csi_migration "true" }}
        CSIMigrationAWS: true
{{- end }}
        SizeMemoryBackedVolumes: {{ .Cluster.ConfigItems.enable_size_memory_backed_volumes }}
{{- if eq .Cluster.ConfigItems.enable_ephemeral_containers "true" }}
        EphemeralContainers: true
{{- end }}
      podPidsLimit: {{ .NodePool.ConfigItems.pod_max_pids }}
      maxPods: {{ nodeCIDRMaxPods (parseInt64 .Cluster.ConfigItems.node_cidr_mask_size) 8 }}
{{- if ne .Cluster.ConfigItems.serialize_image_pulls "true" }}
      serializeImagePulls: false
{{- end }}
      healthzPort: 10248
      healthzBindAddress: "0.0.0.0"
      tlsCertFile: "/etc/kubernetes/ssl/worker.pem"
      tlsPrivateKeyFile: "/etc/kubernetes/ssl/worker-key.pem"
      eventRecordQPS: 50
      eventBurst: 50
      kubeAPIQPS: 50
      kubeAPIBurst: 50
      systemReserved:
        cpu: "{{ .Cluster.ConfigItems.kubelet_system_reserved_cpu }}"
        memory: "{{ .Cluster.ConfigItems.kubelet_system_reserved_memory }}"
      kubeReserved:
        cpu: "{{ .Cluster.ConfigItems.kubelet_kube_reserved_cpu }}"
        memory: "{{ .Cluster.ConfigItems.kubelet_kube_reserved_memory }}"
      allowedUnsafeSysctls:
{{- range $sysctl := split .Cluster.ConfigItems.allowed_unsafe_sysctls "," }}
        - {{$sysctl}}
{{- end }}
      authentication:
        anonymous:
          enabled: true
        webhook:
          enabled: true
          cacheTTL: "2m"
        x509:
          clientCAFile: "/etc/kubernetes/ssl/ca.pem"
      authorization:
        mode: AlwaysAllow
        webhook:
          cacheAuthorizedTTL: "5m"
          cacheUnauthorizedTTL: "30s"
      protectKernelDefaults: true

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
        labels:
          application: kubernetes
          component: kube-apiserver
        annotations:
          kubernetes-log-watcher/scalyr-parser: |
            [{"container": "webhook", "parser": "json-structured-log"}]
          logging/destination: "{{.Cluster.ConfigItems.log_destination_infra}}"
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        hostNetwork: true
        terminationGracePeriodSeconds: 80
        containers:
        - name: kube-apiserver
          image: nonexistent.zalan.do/teapot/kube-apiserver:fixed
          args:
          - --apiserver-count={{ .Values.apiserver_count }}
          - --bind-address=0.0.0.0
          - --etcd-servers={{ .NodePool.ConfigItems.etcd_endpoints }}
{{- if index .Cluster.ConfigItems "etcd_client_ca_cert" }}
          - --etcd-cafile=/etc/kubernetes/ssl/etcd-ca.pem
{{- end }}
{{- if index .Cluster.ConfigItems "etcd_client_apiserver_cert" }}
          - --etcd-certfile=/etc/kubernetes/ssl/etcd-cert.pem
{{- end }}
{{- if index .Cluster.ConfigItems "etcd_client_apiserver_key" }}
          - --etcd-keyfile=/etc/kubernetes/ssl/etcd-key.pem
{{- end }}
          - --etcd-prefix={{ .Cluster.ConfigItems.apiserver_etcd_prefix }}
          - --storage-backend=etcd3
          - --storage-media-type=application/vnd.kubernetes.protobuf
          - --encryption-provider-config=/etc/kubernetes/config/encryption-config.yaml
          - --allow-privileged=true
          - --service-cluster-ip-range=10.5.0.0/16
          - --secure-port=443
          - --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,ExtendedResourceToleration,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,StorageObjectInUseProtection,PodSecurityPolicy,Priority,NodeRestriction{{if eq .Cluster.ConfigItems.event_rate_limit_enable "true"}},EventRateLimit{{end}}
          {{- if eq .Cluster.ConfigItems.event_rate_limit_enable "true"}}
          # This file specifies the EventRateLimit admission plugin's configuration
          - --admission-control-config-file=/etc/kubernetes/config/admission-config.yaml
          {{- end }}
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --runtime-config=policy/v1beta1=true,authorization.k8s.io/v1beta1=true,scheduling.k8s.io/v1alpha1=true,admissionregistration.k8s.io/v1beta1=true
          - --authentication-token-webhook-config-file=/etc/kubernetes/config/authn.yaml
          - --authentication-token-webhook-cache-ttl=10s
          - --cloud-provider=aws
          - --authorization-mode=Node,Webhook,RBAC
          - --authorization-webhook-config-file=/etc/kubernetes/config/authz.yaml
          - --authorization-webhook-version=v1
          - --token-auth-file=/etc/kubernetes/config/tokenfile.csv
{{- if eq .Cluster.ConfigItems.okta_auth_enabled "true" }}
          - --oidc-issuer-url={{.Cluster.ConfigItems.okta_auth_issuer_url}}
          - --oidc-client-id={{.Cluster.ConfigItems.okta_auth_client_id}}
          - --oidc-username-claim=email
          - "--oidc-username-prefix=okta:"
          - --oidc-groups-claim=groups
          - "--oidc-groups-prefix=okta:"
{{- end }}
          - --feature-gates=TTLAfterFinished=true,HPAScaleToZero={{ .Cluster.ConfigItems.enable_hpa_scale_to_zero }},CSIMigration={{ .Cluster.ConfigItems.enable_csi_migration }}{{- if eq .Cluster.ConfigItems.enable_csi_migration "true" }},CSIMigrationAWS=true{{- end }},EphemeralContainers={{ .Cluster.ConfigItems.enable_ephemeral_containers }},HPAContainerMetrics={{ .Cluster.ConfigItems.enable_hpa_container_metrics }},IndexedJob={{ .Cluster.ConfigItems.enable_indexed_jobs }}
          - --service-account-key-file=/etc/kubernetes/ssl/service-account-public-key.pem
          - --service-account-signing-key-file=/etc/kubernetes/ssl/service-account-private-key.pem
          - --service-account-issuer={{ .Cluster.APIServerURL }}
          - --service-account-jwks-uri={{ .Cluster.APIServerURL }}/openid/v1/jwks
          - --service-account-extend-token-expiration={{ .Cluster.ConfigItems.rotate_service_account_tokens_extended_expiration }}
          - --audit-policy-file=/etc/kubernetes/config/audit-policy.yaml
          {{ if eq .Cluster.Environment "e2e" }}
          - --audit-log-path=/var/log/kube-audit.log
          - --audit-log-maxage=0
          - --audit-log-maxbackup=0
          {{ else }}
          - --audit-webhook-config-file=/etc/kubernetes/config/audit.yaml
          - --audit-webhook-mode=batch
          - --audit-webhook-version=audit.k8s.io/v1
          {{ end }}
          # enable aggregated apiservers
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --requestheader-client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --requestheader-allowed-names=aggregator
          - --requestheader-extra-headers-prefix=X-Remote-Extra-
          - --requestheader-group-headers=X-Remote-Group
          - --requestheader-username-headers=X-Remote-User
          - --proxy-client-cert-file=/etc/kubernetes/ssl/proxy-client.pem
          - --proxy-client-key-file=/etc/kubernetes/ssl/proxy-client-key.pem
          # kubelet authentication
          - --kubelet-certificate-authority=/etc/kubernetes/ssl/ca.pem
          - --kubelet-client-certificate=/etc/kubernetes/ssl/kubelet-client.pem
          - --kubelet-client-key=/etc/kubernetes/ssl/kubelet-client-key.pem
          - --shutdown-delay-duration=60s
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          readinessProbe:
            httpGet:
              scheme: HTTPS
              host: 127.0.0.1
              port: 443
              path: /readyz
            initialDelaySeconds: 5
            timeoutSeconds: 5
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/kubernetes/config
            name: kubernetes-configs
            readOnly: true
          - mountPath: /var/run/kmsplugin
            name: var-run-kmsplugin
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
{{- if ne .Cluster.ConfigItems.apiserver_memory_limit_percent "0" }}
            limits:
              memory: {{ .Values.InstanceInfo.MemoryFraction (parseInt64 .Cluster.ConfigItems.apiserver_memory_limit_percent)}}
{{- end }}
        - image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/admission-controller:master-161
          name: admission-controller
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /healthz
              port: 8085
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          env:
            - name: KUBECONFIG
              value: /etc/kubernetes/admission-controller-kubeconfig
          args:
            - --address=:8085
            - --master=https://127.0.0.1:443
            - --tls-cert-file=/etc/kubernetes/ssl/admission-controller.pem
            - --tls-key-file=/etc/kubernetes/ssl/admission-controller-key.pem
{{- if index .Cluster.ConfigItems "application_registry_url" }}
            - --application-registry-url={{.Cluster.ConfigItems.application_registry_url}}
{{- end }}
{{- if index .Cluster.ConfigItems "docker_meta_url" }}
            - --docker-meta-url={{.Cluster.ConfigItems.docker_meta_url}}
{{- end }}
          ports:
            - containerPort: 8085
          volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
            - mountPath: /etc/kubernetes/admission-controller-kubeconfig
              name: admission-controller-kubeconfig
              readOnly: true
{{- if or (eq .Cluster.ConfigItems.routegroups_validation "provisioned") (eq .Cluster.ConfigItems.routegroups_validation "enabled") }}
        - name: routegroups-admission-webhook
          image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/skipper:v0.13.240
          args:
            - webhook
            - --address=:9085
            - --tls-cert-file=/etc/kubernetes/ssl/admission-controller.pem
            - --tls-key-file=/etc/kubernetes/ssl/admission-controller-key.pem
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /healthz
              port: 9085
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          ports:
            - containerPort: 9085
          volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
{{- end}}
        - image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/k8s-authnz-webhook:master-125
          name: webhook
          ports:
          - containerPort: 8081
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8081
            initialDelaySeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8081
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
          args:
            - --node-auth-cluster-id={{.Cluster.ID}}
            - "--node-auth-role-arn=arn:aws:iam::{{accountID .Cluster.InfrastructureAccount}}:role/{{.Cluster.LocalID}}-worker"
            - "--node-auth-rate-limit={{.Cluster.ConfigItems.node_auth_rate_limit}}"
            - --cluster-alias={{.Cluster.Alias}}

            # Collaborator roles
            - --role-mapping=Administrator=cn=Administrator,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --role-mapping=ReadOnly=cn=ReadOnly,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- if eq .Cluster.Environment "production"}}
            - --role-mapping=Collaborator24x7=cn=24x7 Emergency,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --derived-role=CollaboratorEmergency=Collaborator24x7,Emergency
            - --derived-role=CollaboratorManual=Collaborator24x7,Manual
{{- else if eq .Cluster.Environment "test"}}
            - --role-mapping=CollaboratorPowerUser=cn=Deployer,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end }}
{{- if eq .Cluster.ConfigItems.collaborator_administrator_access "true"}}
            - --role-mapping=Administrator=cn=Contributor,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end}}

            # Member roles
            - --role-mapping=Administrator=cn=Administrator,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- if eq .Cluster.Environment "production"}}
            - --role-mapping=Manual=cn=Manual,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --role-mapping=Emergency=cn=Emergency,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- else }}
            - --role-mapping=PowerUser=cn=PowerUser,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end }}
            - --role-mapping=ReadOnly=cn=ReadOnly,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
            # enable legacy serviceaccounts for smooth RBAC migration
{{ if eq .Cluster.ConfigItems.enable_operator_sa "true"}}
            - --enable-operator-sa
{{ end }}
{{ if eq .Cluster.ConfigItems.enable_default_sa "true"}}
            - --enable-default-sa
{{ end }}
            - --system-users=zalando-iam:zalando:service:k8sapi_credentials-provider
            - --system-users=system:serviceaccount:api-infrastructure:api-monitoring-controller
            - --collaborator-app-users=zalando-iam:zalando:service:stups_scalyr-key-rotation
          env:
            - name: TEAMS_API_URL
              value: https://teams.auth.zalando.com
            - name: TOKENINFO_URLS
              value: https://identity.zalando.com=http://127.0.0.1:9021/oauth2/tokeninfo{{ if ne .Cluster.Environment "production" }},https://sandbox.identity.zalando.com=http://127.0.0.1:9022/oauth2/tokeninfo{{end}}
            - name: USER_GROUPS
              value: stups_cluster-lifecycle-manager=system:masters{{if eq .Cluster.Environment "e2e"}},stups_kubernetes-on-aws-e2e=system:masters,stups_kubernetes=system:masters{{end}}
          volumeMounts:
          - mountPath: /etc/kubernetes/config
            name: kubernetes-configs
            readOnly: true
        - image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/foundation/platform-iam-tokeninfo:master-19
          name: tokeninfo
          ports:
            - containerPort: 9021
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /health
              port: 9021
            periodSeconds: 3
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /health
              port: 9021
            periodSeconds: 3
            failureThreshold: 2
          resources:
            requests:
              cpu: 50m
              memory: 20Mi
          env:
            - name: OPENID_PROVIDER_CONFIGURATION_URL
              value: https://identity.zalando.com/.well-known/openid-configuration
            - name: BUSINESS_PARTNERS
              value: {{ .Cluster.ConfigItems.apiserver_business_partner_ids }}
{{ if ne .Cluster.Environment "production" }}
        - name: tokeninfo-sandbox
          image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/foundation/platform-iam-tokeninfo:master-19
          ports:
          - containerPort: 9022
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /health
              port: 9022
            periodSeconds: 3
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /health
              port: 9022
            periodSeconds: 3
            failureThreshold: 2
          resources:
            requests:
              cpu: 50m
              memory: 20Mi
          env:
          - name: OPENID_PROVIDER_CONFIGURATION_URL
            value: https://sandbox.identity.zalando.com/.well-known/openid-configuration
          - name: ISSUER
            value: "https://sandbox.identity.zalando.com"
          - name: LISTEN_ADDRESS
            value: ":9022"
          - name: BUSINESS_PARTNERS
            value: {{ .Cluster.ConfigItems.apiserver_business_partner_ids }}
{{ end }}
        - name: skipper-proxy
          image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/skipper:v0.13.240
          args:
          - skipper
          - -access-log-strip-query
          - -address=:8443
          - -support-listener=:9911
          - -tls-cert=/etc/kubernetes/ssl/apiserver.pem
          - -tls-key=/etc/kubernetes/ssl/apiserver-key.pem
          - -insecure
          - -experimental-upgrade
          - -runtime-metrics
          - -enable-connection-metrics
          - -enable-prometheus-metrics
          - -write-timeout-server=60m
          # wait-for-healthcheck-interval delays termination, since it's
          # integrated with the health endpoint, using that instead of a
          # preStop hook.
          - -wait-for-healthcheck-interval=60s
          - -inline-routes
          - |
            s: JWTPayloadAllKV("iss", "kubernetes/serviceaccount")
              -> enableAccessLog()
              -> {{ if eq .ConfigItems.allow_external_service_accounts "true" }}"https://127.0.0.1:443"{{ else }}status(401) -> <shunt>{{ end }};
            h: Path("/kube-system/readyz")
              -> setPath("/readyz")
              -> disableAccessLog()
              -> "https://127.0.0.1:443";
            all: *
              -> disableAccessLog()
              -> "https://127.0.0.1:443";
          ports:
          - containerPort: 8443
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /kube-system/readyz
              port: 8443
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 250Mi
          securityContext:
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
        - name: skipper-metrics
          image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/skipper:v0.13.240
          args:
          - skipper
          - -access-log-strip-query
          - -address=:9005
          - -support-listener=:9905
          - -insecure
          - -runtime-metrics
          - -enable-connection-metrics
          - -enable-prometheus-metrics
          - -write-timeout-server=60m
          - -inline-routes
          - |
            admission_controller: Path("/admission-controller")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "https://127.0.0.1:8085";
            auth_webhook: Path("/auth-webhook")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "http://127.0.0.1:8081";
            routegroups_admission_webhook: Path("/routegroups-admission-webhook")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "https://127.0.0.1:9085";
            aws_encryption_provider: Path("/aws-encryption-provider")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "http://localhost:8086";
            skipper_proxy: Path("/skipper-proxy")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "http://127.0.0.1:9911";
            skipper_metrics: Path("/skipper-metrics")
              -> disableAccessLog()
              -> setPath("/metrics")
              -> "http://127.0.0.1:9905";
            healthz: Path("/healthz")
              -> disableAccessLog()
              -> status(200)
              -> inlineContent("ok")
              -> <shunt>;
          ports:
          - containerPort: 9005
          readinessProbe:
            httpGet:
              path: /healthz
              port: 9005
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 250Mi
          securityContext:
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
        - name: aws-encryption-provider
          image: 926694233939.dkr.ecr.eu-central-1.amazonaws.com/production_namespace/teapot/aws-encryption-provider:master-3
          command:
          - /aws-encryption-provider
          - --key=arn:aws:kms:{{ .Cluster.Region }}:{{ .Cluster.InfrastructureAccount | getAWSAccountID }}:key/{{ .Values.ClusterStackOutputs.EtcdEncryptionKey }}
          - --region={{ .Cluster.Region }}
          - --listen=/var/run/kmsplugin/socket.sock
          - --health-port=:8086
          ports:
          - containerPort: 8086
            protocol: TCP
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8086
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
          volumeMounts:
          - mountPath: /var/run/kmsplugin
            name: var-run-kmsplugin
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /etc/kubernetes/config
          name: kubernetes-configs
        - name: var-run-kmsplugin
          hostPath:
            path: /var/run/kmsplugin
            type: DirectoryOrCreate
        - hostPath:
            path: /etc/kubernetes/admission-controller-kubeconfig
            type: File
          name: admission-controller-kubeconfig

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
        labels:
          application: kubernetes
          component: kube-controller-manager
        annotations:
          logging/destination: "{{.Cluster.ConfigItems.log_destination_infra}}"
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        containers:
        - name: kube-controller-manager
          image: nonexistent.zalan.do/teapot/{{if eq .Cluster.ConfigItems.kubernetes_controller_manager_image "zalando" }}kube-controller-manager-internal{{else}}kube-controller-manager{{end}}:fixed
          args:
          - --kubeconfig=/etc/kubernetes/controller-manager-kubeconfig
          - --leader-elect=true
          - --service-account-private-key-file=/etc/kubernetes/ssl/service-account-private-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          - --cloud-provider=aws
          - --cloud-config=/etc/kubernetes/cloud-config.ini
          - --feature-gates=TTLAfterFinished=true,CSIMigration={{ .Cluster.ConfigItems.enable_csi_migration }}{{- if eq .Cluster.ConfigItems.enable_csi_migration "true" }},CSIMigrationAWS=true{{- end }},IndexedJob={{ .Cluster.ConfigItems.enable_indexed_jobs }}
          - --use-service-account-credentials=true
          - --configure-cloud-routes=false
          - --allocate-node-cidrs=true
          - --cluster-cidr=10.2.0.0/15
          - --node-cidr-mask-size={{ .Cluster.ConfigItems.node_cidr_mask_size }}
          - --kube-api-qps=50
          - --terminated-pod-gc-threshold=500
          - --horizontal-pod-autoscaler-sync-period={{ .Cluster.ConfigItems.horizontal_pod_autoscaler_sync_period }}
          - --horizontal-pod-autoscaler-tolerance={{ .Cluster.ConfigItems.horizontal_pod_autoscaler_tolerance }}
          - --horizontal-pod-autoscaler-downscale-stabilization={{ .Cluster.ConfigItems.horizontal_pod_downscale_stabilization }}
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              scheme: HTTPS
              path: /healthz
              port: 10257
            initialDelaySeconds: 15
            timeoutSeconds: 15
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/kubernetes
            name: config
            readOnly: true
        hostNetwork: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /etc/kubernetes
          name: config

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-scheduler.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
        labels:
          application: kubernetes
          component: kube-scheduler
        annotations:
          logging/destination: "{{.Cluster.ConfigItems.log_destination_infra}}"
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: nonexistent.zalan.do/teapot/{{if eq .Cluster.ConfigItems.kubernetes_scheduler_image "zalando" }}kube-scheduler-internal{{else}}kube-scheduler{{end}}:fixed
          args:
          - --kubeconfig=/etc/kubernetes/scheduler-kubeconfig
          - --leader-elect=true
          - --feature-gates=NonPreemptingPriority=true
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          env:
          - name: KUBE_MAX_PD_VOLS
            value: "26"
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              scheme: HTTPS
              path: /healthz
              port: 10259
            initialDelaySeconds: 15
            timeoutSeconds: 15
          volumeMounts:
          - mountPath: /etc/kubernetes/scheduler-kubeconfig
            name: kubeconfig
            readOnly: true
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /etc/kubernetes/scheduler-kubeconfig
            type: File
          name: kubeconfig

  - owner: root:root
    path: /etc/kubernetes/config/tokenfile.csv
    permissions: 0600
    content: ""

  - owner: root:root
    path: /etc/kubernetes/config/audit.yaml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: audit
        cluster:
          server: http://127.0.0.1:8889/audit
      contexts:
      - name: audit
        context:
          cluster: audit
          user: audit
      current-context: audit

  - owner: root:root
    path: /etc/kubernetes/config/audit-policy.yaml
    content: |
      apiVersion: audit.k8s.io/v1beta1
      kind: Policy
      rules:
        # The following requests were manually identified as high-volume and low-risk,
        # so drop them.
        - level: None
          users: ["system:kube-proxy"]
          verbs: ["watch"]
          resources:
            - group: "" # core
              resources: ["endpoints", "services", "services/status"]
        # don't audit any kubelet events
        # only enable it in e2e because we use kubelet as the identity for running e2e
        {{ if ne .Cluster.Environment "e2e" }}
        - level: None
          users: ["kubelet"] # legacy kubelet identity
        {{ end }}
        # don't audit events from the system:unsecured user. This is the user
        # used when connecting to the apiserver over localhost, and will
        # usuaully be done by the local kubelet.
        - level: None
          users: ["system:unsecured"]
        # don't audit events from the system:apiserver user
        - level: None
          users: ["system:apiserver"]
        {{ if eq .ConfigItems.audit_pod_events "true" }}
        # audit pod events
        - level: Request
          omitStages:
            - "RequestReceived"
          verbs: ["create", "delete", "update", "patch", "deletecollection"]
          resources:
            - group: "" # core
              resources: ["pods"]
        {{ end }}
        # don't audit any kube-controller-manager events
        - level: None
          users: ["system:kube-controller-manager"]
        - level: None
          userGroups: ["system:nodes"]
          verbs: ["get"]
          resources:
            - group: "" # core
              resources: ["nodes", "nodes/status"]
        - level: None
          users:
            - system:kube-controller-manager
            - system:kube-scheduler
            - system:serviceaccount:kube-system:endpoint-controller
          verbs: ["get", "update"]
          namespaces: ["kube-system"]
          resources:
            - group: "" # core
              resources: ["endpoints"]
        - level: None
          users: ["system:apiserver"]
          verbs: ["get"]
          resources:
            - group: "" # core
              resources: ["namespaces", "namespaces/status", "namespaces/finalize"]
        # Don't log HPA fetching metrics.
        - level: None
          users:
            - system:kube-controller-manager
          verbs: ["get", "list"]
          resources:
            - group: "metrics.k8s.io"
        # Don't log these read-only URLs.
        - level: None
          nonResourceURLs:
            - /healthz*
            - /version
            - /swagger*
        # Don't log events requests.
        - level: None
          resources:
            - group: "" # core
              resources: ["events"]
{{ if ne .Cluster.ConfigItems.auditlog_read_access "true" }}
        # Don't audit events from system users in kube-system
        # unless auditlog_read_access=true
        - level: None
          userGroups: ["system:serviceaccounts:kube-system"]
{{ end }}
        # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data,
        # so only log at the Metadata level.
        - level: Metadata
          resources:
            - group: "" # core
              resources: ["secrets", "configmaps", "serviceaccounts/token"]
            - group: authentication.k8s.io
              resources: ["tokenreviews"]
          omitStages:
            - "RequestReceived"
{{ if eq .Cluster.ConfigItems.auditlog_read_access "true" }}
        - level: Request
          verbs: ["watch", "list", "get"]
          omitStages:
          - "RequestReceived"
{{ else }}
        # Don't audit read-only events.
        - level: None
          verbs: ["watch", "list", "get"]
{{ end }}
        # Default level for all other requests.
        - level: Request
          omitStages:
            - "RequestReceived"

  - owner: root:root
    path: /etc/kubernetes/config/encryption-config.yaml
    permissions: '0400'
    content: |
      apiVersion: apiserver.config.k8s.io/v1
      kind: EncryptionConfiguration
      resources:
        - resources:
          - secrets
          providers:
      {{- if ne .Cluster.ConfigItems.enable_encryption "true" }}
          - identity: {}
      {{- end }}
          - kms:
              name: aws-encryption-provider
              endpoint: unix:///var/run/kmsplugin/socket.sock
              cachesize: 50000
              timeout: 3s
      {{- if eq .Cluster.ConfigItems.enable_encryption "true" }}
          - identity: {}
      {{- end }}

{{ if eq .Cluster.ConfigItems.event_rate_limit_enable "true"}}
  # Enabling EventRateLimit admission plugin
  # Reference: https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#eventratelimit
  - owner: root:root
    path: /etc/kubernetes/config/admission-config.yaml
    content: |
      apiVersion: apiserver.config.k8s.io/v1
      kind: AdmissionConfiguration
      plugins:
        - name: EventRateLimit
          path: /etc/kubernetes/config/event-config.yaml

  - owner: root:root
    path: /etc/kubernetes/config/event-config.yaml
    content: |
      apiVersion: eventratelimit.admission.k8s.io/v1alpha1
      kind: Configuration
      limits:
        - type: Server
          qps: {{ .Cluster.ConfigItems.event_rate_limit_config_qps }}
          burst: {{ .Cluster.ConfigItems.event_rate_limit_config_burst }}
{{ end }}

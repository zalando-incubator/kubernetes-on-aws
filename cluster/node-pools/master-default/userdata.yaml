#cloud-config
write_files:
  - owner: root:root
    path: /etc/kubernetes/secrets.env
    content: |
      NODEPOOL_TAINTS=node.kubernetes.io/role=master:NoSchedule{{if index .NodePool.ConfigItems "taints"}},{{.NodePool.ConfigItems.taints}}{{end}}
      NODE_LABELS=master=true,node.kubernetes.io/distro=ubuntu,cluster-lifecycle-controller.zalan.do/decommission-priority=999,{{ .Values.node_labels }}{{if index .NodePool.ConfigItems "labels"}},{{.NodePool.ConfigItems.labels}}{{end}}
      NODEPOOL_NAME={{ .NodePool.Name }}
      KUBELET_ROLE=master

  - owner: root:root
    path: /etc/kuberuntu/s3-certs.env
    content: |
      S3_CERTS_BUCKET={{ .S3GeneratedFilesPath }}
      AWS_DEFAULT_REGION={{ .Cluster.Region }}

  - owner: root:root
    path: /etc/kubernetes/kubeconfig
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: local
        cluster:
          server: http://127.0.0.1:8080
      users:
      - name: kubelet
      contexts:
      - context:
          cluster: local
          user: kubelet

  - owner: root:root
    path: /etc/kubernetes/config/kubelet.yaml
    content: |
      # https://github.com/kubernetes/kubernetes/blob/v1.13.6/staging/src/k8s.io/kubelet/config/v1beta1/types.go
      apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      staticPodPath: "/etc/kubernetes/manifests"
      clusterDomain: cluster.local
{{- if not (index .Cluster.ConfigItems "enable_cfs_quota") }}
      cpuCFSQuota: false
{{- end }}
      featureGates:
        BoundServiceAccountTokenVolume: {{ .Cluster.ConfigItems.rotate_service_account_tokens }}
        CSIMigration: {{ .Cluster.ConfigItems.enable_csi_migration }}
{{- if eq .Cluster.ConfigItems.enable_ephemeral_containers "true" }}
        EphemeralContainers: true
{{- end }}
      podPidsLimit: {{ .NodePool.ConfigItems.pod_max_pids }}
      maxPods: {{ nodeCIDRMaxPods (parseInt64 .Cluster.ConfigItems.node_cidr_mask_size) 8 }}
{{- if ne .Cluster.ConfigItems.serialize_image_pulls "true" }}
      serializeImagePulls: false
{{- end }}
      healthzPort: 10248
      healthzBindAddress: "0.0.0.0"
      tlsCertFile: "/etc/kubernetes/ssl/worker.pem"
      tlsPrivateKeyFile: "/etc/kubernetes/ssl/worker-key.pem"
      eventRecordQPS: 50
      eventBurst: 50
      kubeAPIQPS: 50
      kubeAPIBurst: 50
      systemReserved:
        cpu: "100m"
        memory: "164Mi"
      kubeReserved:
        cpu: "100m"
        memory: "282Mi"
      allowedUnsafeSysctls:
        - net.ipv4.tcp_keepalive_time
        - net.ipv4.tcp_keepalive_intvl
        - net.ipv4.tcp_keepalive_probes
      authentication:
        anonymous:
          enabled: true
        webhook:
          enabled: true
          cacheTTL: "2m"
        x509:
          clientCAFile: "/etc/kubernetes/ssl/ca.pem"
      authorization:
        mode: AlwaysAllow
        webhook:
          cacheAuthorizedTTL: "5m"
          cacheUnauthorizedTTL: "30s"

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
        labels:
          application: kube-apiserver
        annotations:
          kubernetes-log-watcher/scalyr-parser: |
            [{"container": "webhook", "parser": "json-structured-log"}]
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        hostNetwork: true
        terminationGracePeriodSeconds: 80
        containers:
        - name: kube-apiserver
          image: nonexistent.zalan.do/teapot/kube-apiserver:fixed
          args:
          - --apiserver-count={{ .Values.apiserver_count }}
          - --bind-address=0.0.0.0
          - --insecure-bind-address=0.0.0.0
          - --etcd-servers={{ .NodePool.ConfigItems.etcd_endpoints }}
{{- if index .Cluster.ConfigItems "etcd_client_ca_cert" }}
          - --etcd-cafile=/etc/kubernetes/ssl/etcd-ca.pem
{{- end }}
{{- if index .Cluster.ConfigItems "etcd_client_apiserver_cert" }}
          - --etcd-certfile=/etc/kubernetes/ssl/etcd-cert.pem
{{- end }}
{{- if index .Cluster.ConfigItems "etcd_client_apiserver_key" }}
          - --etcd-keyfile=/etc/kubernetes/ssl/etcd-key.pem
{{- end }}
          - --etcd-prefix={{ .Cluster.ConfigItems.apiserver_etcd_prefix }}
          - --storage-backend=etcd3
          - --storage-media-type=application/vnd.kubernetes.protobuf
          - --encryption-provider-config=/etc/kubernetes/config/encryption-config.yaml
          - --allow-privileged=true
          - --service-cluster-ip-range=10.3.0.0/16
          - --secure-port=443
          - --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,ExtendedResourceToleration,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,StorageObjectInUseProtection,PodSecurityPolicy,ImagePolicyWebhook,Priority
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --runtime-config=extensions/v1beta1/networkpolicies=true,batch/v2alpha1=true,policy/v1beta1=true,imagepolicy.k8s.io/v1alpha1=true,authorization.k8s.io/v1beta1=true,scheduling.k8s.io/v1alpha1=true,admissionregistration.k8s.io/v1beta1=true
          - --authentication-token-webhook-config-file=/etc/kubernetes/config/authn.yaml
          - --authentication-token-webhook-cache-ttl=10s
          - --cloud-provider=aws
          - --authorization-mode=Webhook,RBAC
          - --authorization-webhook-config-file=/etc/kubernetes/config/authz.yaml
          - --authorization-webhook-version=v1
          - --admission-control-config-file=/etc/kubernetes/config/image-policy-webhook.yaml
          - --feature-gates=TTLAfterFinished=true,BoundServiceAccountTokenVolume={{ .Cluster.ConfigItems.rotate_service_account_tokens }},HPAScaleToZero={{ .Cluster.ConfigItems.enable_hpa_scale_to_zero }},VolumeSnapshotDataSource={{ .Cluster.ConfigItems.enable_csi_migration }},CSIMigration={{ .Cluster.ConfigItems.enable_csi_migration }},NonPreemptingPriority=true,EphemeralContainers={{ .Cluster.ConfigItems.enable_ephemeral_containers }}
          - --anonymous-auth=false
          - --service-account-key-file=/etc/kubernetes/ssl/service-account-public-key.pem
          {{- if eq .Cluster.ConfigItems.rotate_service_account_tokens "true" }}
          - --service-account-signing-key-file=/etc/kubernetes/ssl/service-account-private-key.pem
          - --service-account-issuer=kubernetes/serviceaccount
          {{- end }}
          {{- if or (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam "true") (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam_userdata "true") }}
          - --service-account-signing-key-file=/etc/kubernetes/ssl/service-account-private-key.pem
          - --service-account-issuer={{ .Cluster.APIServerURL }}
          {{- end }}
          {{ if and (ne .Cluster.ConfigItems.audittrail_url "") (ne .Cluster.Environment "e2e") }}
          - --audit-webhook-config-file=/etc/kubernetes/config/audit.yaml
          - --audit-webhook-mode=batch
          - --audit-webhook-version=audit.k8s.io/v1
          - --audit-policy-file=/etc/kubernetes/config/audit-policy.yaml
          {{ end }}
          {{ if eq .Cluster.Environment "e2e" }}
          - --audit-log-path=/var/log/kube-audit.log
          - --audit-log-maxage=0
          - --audit-log-maxbackup=0
          - --audit-policy-file=/etc/kubernetes/config/audit-policy.yaml
          {{ else if and (eq .Cluster.ConfigItems.enable_default_sa "true") (eq .Cluster.ConfigItems.auditlog_read_access "true") }}
          - --audit-log-path=/dev/stdout
          - --audit-log-maxage=0
          - --audit-log-maxbackup=0
          {{ if eq .Cluster.ConfigItems.audittrail_url "" }}
          - --audit-policy-file=/etc/kubernetes/config/audit-policy-ro.yaml
          {{ end }}
          {{ end }}
          # enable aggregated apiservers
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --requestheader-client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --requestheader-allowed-names=aggregator
          - --requestheader-extra-headers-prefix=X-Remote-Extra-
          - --requestheader-group-headers=X-Remote-Group
          - --requestheader-username-headers=X-Remote-User
          - --proxy-client-cert-file=/etc/kubernetes/ssl/proxy-client.pem
          - --proxy-client-key-file=/etc/kubernetes/ssl/proxy-client-key.pem
          # kubelet authentication
          - --kubelet-certificate-authority=/etc/kubernetes/ssl/ca.pem
          - --kubelet-client-certificate=/etc/kubernetes/ssl/kubelet-client.pem
          - --kubelet-client-key=/etc/kubernetes/ssl/kubelet-client-key.pem
          - --shutdown-delay-duration=60s
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              port: 8080
              path: /healthz
            initialDelaySeconds: 120
            timeoutSeconds: 15
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/kubernetes/config
            name: kubernetes-configs
            readOnly: true
          - mountPath: /var/run/kmsplugin
            name: var-run-kmsplugin
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
        - image: registry.opensource.zalan.do/teapot/admission-controller:master-86
          name: admission-controller
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /healthz
              port: 8085
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          args:
            - --address=:8085
            - --master=http://127.0.0.1:8080
            - --tls-cert-file=/etc/kubernetes/ssl/admission-controller.pem
            - --tls-key-file=/etc/kubernetes/ssl/admission-controller-key.pem
{{- if eq .Cluster.ConfigItems.teapot_admission_controller_validate_application_label "true" }}
            - --application-registry-url=http://127.0.0.1:8285/
{{- end }}
          ports:
            - containerPort: 8085
          volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
{{- if or (eq .Cluster.ConfigItems.routegroups_validation "provisioned") (eq .Cluster.ConfigItems.routegroups_validation "enabled") }}
        - name: routegroups-admission-webhook
          image: registry.opensource.zalan.do/pathfinder/skipper:v0.11.151
          args:
            - webhook
            - --address=:9085
            - --tls-cert-file=/etc/kubernetes/ssl/admission-controller.pem
            - --tls-key-file=/etc/kubernetes/ssl/admission-controller-key.pem
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /healthz
              port: 9085
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          ports:
            - containerPort: 9085
          volumeMounts:
            - mountPath: /etc/kubernetes/ssl
              name: ssl-certs-kubernetes
              readOnly: true
{{- end}}
        - image: registry.opensource.zalan.do/teapot/k8s-authnz-webhook:v0.8.0
          name: webhook
          ports:
          - containerPort: 8081
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8081
            initialDelaySeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8081
            initialDelaySeconds: 5
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
          args:
            - --tokens-file=/etc/kubernetes/config/tokenfile.csv

            # Collaborator roles
            - --role-mapping=Administrator=cn=Administrator,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --role-mapping=ReadOnly=cn=ReadOnly,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- if eq .Cluster.Environment "production"}}
            - --role-mapping=Collaborator24x7=cn=24x7 Emergency,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --derived-role=CollaboratorEmergency=Collaborator24x7,Emergency
            - --derived-role=CollaboratorManual=Collaborator24x7,Manual
{{- else if eq .Cluster.Environment "test"}}
            - --role-mapping=CollaboratorPowerUser=cn=Deployer,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end }}
{{- if eq .Cluster.ConfigItems.collaborator_administrator_access "true"}}
            - --role-mapping=Administrator=cn=Contributor,ou=collaborators,ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end}}

            # Member roles
            - --role-mapping=Administrator=cn=Administrator,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- if eq .Cluster.Environment "production"}}
            - --role-mapping=Manual=cn=Manual,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
            - --role-mapping=Emergency=cn=Emergency,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- else }}
            - --role-mapping=PowerUser=cn=PowerUser,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
{{- end }}
            - --role-mapping=ReadOnly=cn=ReadOnly,ou={{.Cluster.ID}},ou=Kubernetes,ou=apps,dc=zalando,dc=net
            # enable legacy serviceaccounts for smooth RBAC migration
{{ if eq .Cluster.ConfigItems.enable_operator_sa "true"}}
            - --enable-operator-sa
{{ end }}
{{ if eq .Cluster.ConfigItems.enable_default_sa "true"}}
            - --enable-default-sa
{{ end }}
{{ if eq .Cluster.ConfigItems.enable_cdp_sa "true"}}
            - --enable-cdp-sa
{{ end }}
            - --system-users=zalando-iam:zalando:service:credentials-provider
            - --system-users=system:serviceaccount:api-infrastructure:api-monitoring-controller
            - --collaborator-app-users=zalando-iam:zalando:service:stups_scalyr-key-rotation
          env:
            - name: TEAMS_API_URL
              value: https://teams.auth.zalando.com
            - name: TOKENINFO_URLS
              value: https://identity.zalando.com=http://127.0.0.1:9021/oauth2/tokeninfo{{ if ne .Cluster.Environment "production" }},https://sandbox.identity.zalando.com=http://127.0.0.1:9022/oauth2/tokeninfo{{end}}
            - name: USER_GROUPS
              value: kubelet=system:masters,stups_cluster-lifecycle-manager=system:masters
          volumeMounts:
          - mountPath: /etc/kubernetes/config
            name: kubernetes-configs
            readOnly: true
        - image: registry.opensource.zalan.do/foundation/platform-iam-tokeninfo:2fca26c
          name: tokeninfo
          ports:
            - containerPort: 9021
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /health
              port: 9021
            periodSeconds: 3
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /health
              port: 9021
            periodSeconds: 3
            failureThreshold: 2
          resources:
            requests:
              cpu: 50m
              memory: 20Mi
          env:
            - name: OPENID_PROVIDER_CONFIGURATION_URL
              value: https://identity.zalando.com/.well-known/openid-configuration
            - name: BUSINESS_PARTNERS
              value: {{ .Cluster.ConfigItems.apiserver_business_partner_ids }}
{{ if ne .Cluster.Environment "production" }}
        - name: tokeninfo-sandbox
          image: registry.opensource.zalan.do/foundation/platform-iam-tokeninfo:2fca26c
          ports:
          - containerPort: 9022
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          livenessProbe:
            httpGet:
              path: /health
              port: 9022
            periodSeconds: 3
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /health
              port: 9022
            periodSeconds: 3
            failureThreshold: 2
          resources:
            requests:
              cpu: 50m
              memory: 20Mi
          env:
          - name: OPENID_PROVIDER_CONFIGURATION_URL
            value: https://sandbox.identity.zalando.com/.well-known/openid-configuration
          - name: ISSUER
            value: "https://sandbox.identity.zalando.com"
          - name: LISTEN_ADDRESS
            value: ":9022"
          - name: BUSINESS_PARTNERS
            value: {{ .Cluster.ConfigItems.apiserver_business_partner_ids }}
{{ end }}
        - image: registry.opensource.zalan.do/teapot/image-policy-webhook:v0.5.4
          name: image-policy-webhook
          args:
          - --policy={{ .Cluster.ConfigItems.image_policy }}
          - --failure-policy=fail
          - --trusted-ttl=30s
          ports:
          - containerPort: 8083
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
        - name: skipper-proxy
          image: registry.opensource.zalan.do/pathfinder/skipper:v0.11.150
          args:
          - skipper
          - -access-log-strip-query
          - -address=:8443
          - -support-listener=:9911
          - -tls-cert=/etc/kubernetes/ssl/apiserver.pem
          - -tls-key=/etc/kubernetes/ssl/apiserver-key.pem
          - -insecure
          - -experimental-upgrade
          - -runtime-metrics
          - -enable-connection-metrics
          - -enable-prometheus-metrics
          - -write-timeout-server=60m
          - -wait-for-healthcheck-interval=60s
          - -inline-routes
          - |
            s: JWTPayloadAllKV("iss", "kubernetes/serviceaccount")
              -> enableAccessLog()
              -> {{ if eq .ConfigItems.allow_external_service_accounts "true" }}"https://127.0.0.1:443"{{ else }}status(401) -> <shunt>{{ end }};
            h: Path("/kube-system/healthz")
              -> setPath("/healthz")
              -> disableAccessLog()
              -> "http://127.0.0.1:8080";
          {{- if or (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam "true") (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam_userdata "true") }}
            o: Path("/.well-known/openid-configuration")
              -> setResponseHeader("Content-Type", "application/json")
              -> static("/.well-known/", "/var/www/openid-configuration/")
              -> <shunt>;
            k: Path("/openid-configuration/*")
              -> setResponseHeader("Content-Type", "application/json")
              -> static("/openid-configuration/", "/var/www/openid-configuration/")
              -> <shunt>;
          {{- end }}
            all: *
              -> disableAccessLog()
              -> "https://127.0.0.1:443";
          ports:
          - containerPort: 8443
          readinessProbe:
            httpGet:
              scheme: HTTPS
              path: /kube-system/healthz
              port: 8443
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 250Mi
          securityContext:
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
{{- if or (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam "true") (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam_userdata "true") }}
          - mountPath: /var/www/openid-configuration
            name: openid-configuration
            readOnly: true
{{- end }}
        - name: aws-encryption-provider
          image: registry.opensource.zalan.do/teapot/aws-encryption-provider:master-1
          command:
          - /aws-encryption-provider
          - --key=arn:aws:kms:{{ .Cluster.Region }}:{{ .Cluster.InfrastructureAccount | getAWSAccountID }}:key/{{ .Values.ClusterStackOutputs.EtcdEncryptionKey }}
          - --region={{ .Cluster.Region }}
          - --listen=/var/run/kmsplugin/socket.sock
          - --health-port=:8086
          ports:
          - containerPort: 8086
            protocol: TCP
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c",  " sleep 60"]
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8086
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
          volumeMounts:
          - mountPath: /var/run/kmsplugin
            name: var-run-kmsplugin
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /etc/kubernetes/config
          name: kubernetes-configs
        {{- if or (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam "true") (eq .Cluster.ConfigItems.teapot_admission_controller_service_account_iam_userdata "true") }}
        - hostPath:
            path: /var/www/openid-configuration
          name: openid-configuration
        {{- end }}
        - name: var-run-kmsplugin
          hostPath:
            path: /var/run/kmsplugin
            type: DirectoryOrCreate

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
        labels:
          application: kube-controller-manager
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        containers:
        - name: kube-controller-manager
          image: nonexistent.zalan.do/teapot/kube-controller-manager:fixed
          args:
          - --kubeconfig=/etc/kubernetes/controller-kubeconfig
          - --leader-elect=true
          - --service-account-private-key-file=/etc/kubernetes/ssl/service-account-private-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          - --cloud-provider=aws
          - --cloud-config=/etc/kubernetes/cloud-config.ini
          - --feature-gates=TTLAfterFinished=true,BoundServiceAccountTokenVolume={{ .Cluster.ConfigItems.rotate_service_account_tokens }},CSIMigration={{ .Cluster.ConfigItems.enable_csi_migration }}
          - --horizontal-pod-autoscaler-use-rest-clients=true
          - --use-service-account-credentials=true
          - --configure-cloud-routes=false
          - --allocate-node-cidrs=true
          - --cluster-cidr=10.2.0.0/16
          - --node-cidr-mask-size={{ .Cluster.ConfigItems.node_cidr_mask_size }}
          - --kube-api-qps=50
          - --terminated-pod-gc-threshold=500
          - --horizontal-pod-autoscaler-use-rest-clients=true
          - --horizontal-pod-autoscaler-sync-period={{ .Cluster.ConfigItems.horizontal_pod_autoscaler_sync_period }}
          - --horizontal-pod-autoscaler-tolerance={{ .Cluster.ConfigItems.horizontal_pod_autoscaler_tolerance }}
          - --horizontal-pod-autoscaler-downscale-stabilization={{ .Cluster.ConfigItems.horizontal_pod_downscale_stabilization }}
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 15
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/kubernetes
            name: kubeconfig
            readOnly: true
        hostNetwork: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /etc/kubernetes
          name: kubeconfig

  - owner: root:root
    path: /etc/kubernetes/manifests/kube-scheduler.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
        labels:
          application: kube-scheduler
      spec:
        priorityClassName: system-node-critical
        tolerations:
        - key: node.kubernetes.io/role
          value: master
          effect: NoSchedule
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: nonexistent.zalan.do/teapot/kube-scheduler:fixed
          args:
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          - --feature-gates=BoundServiceAccountTokenVolume={{ .Cluster.ConfigItems.rotate_service_account_tokens }},NonPreemptingPriority=true
          - --profiling={{ .Cluster.ConfigItems.enable_control_plane_profiling }}
          env:
          - name: KUBE_MAX_PD_VOLS
            value: "26"
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 15

  - owner: root:root
    path: /etc/kubernetes/config/tokenfile.csv
    content: |
      {{ .Cluster.ConfigItems.worker_shared_secret }},kubelet,kubelet

  - owner: root:root
    path: /etc/kubernetes/config/image-policy-webhook.yaml
    content: |
      imagePolicy:
        kubeConfigFile: /etc/kubernetes/config/image-policy-webhook-kubeconfig.yaml
        allowTTL: 2
        denyTTL: 2
        retryBackoff: 500
        defaultAllow: false

  - owner: root:root
    path: /etc/kubernetes/config/image-policy-webhook-kubeconfig.yaml
    content: |
      clusters:
        - name: image-policy-webhook
          cluster:
            server: http://127.0.0.1:8083/admit
      users:
        - name: image-policy-webhook
      current-context: image-policy-webhook
      contexts:
      - context:
          cluster: image-policy-webhook
          user: image-policy-webhook
        name: image-policy-webhook

  - owner: root:root
    path: /etc/kubernetes/config/audit.yaml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: audit
        cluster:
          server: http://127.0.0.1:8889/audit
      contexts:
      - name: audit
        context:
          cluster: audit
          user: audit
      current-context: audit

  - owner: root:root
    path: /etc/kubernetes/config/audit-policy.yaml
    content: |
      apiVersion: audit.k8s.io/v1beta1
      kind: Policy
      rules:
        # The following requests were manually identified as high-volume and low-risk,
        # so drop them.
        - level: None
          users: ["system:kube-proxy"]
          verbs: ["watch"]
          resources:
            - group: "" # core
              resources: ["endpoints", "services", "services/status"]
        # don't audit any kubelet events
        # only enable it in e2e because we use kubelet as the identity for running e2e
        {{ if ne .Cluster.Environment "e2e" }}
        - level: None
          users: ["kubelet"] # legacy kubelet identity
        {{ end }}
        # don't audit events from the system:unsecured user. This is the user
        # used when connecting to the apiserver over localhost, and will
        # usuaully be done by the local kubelet.
        - level: None
          users: ["system:unsecured"]
        # don't audit events from the system:apiserver user
        - level: None
          users: ["system:apiserver"]
        {{ if eq .ConfigItems.audit_pod_events "true" }}
        # audit pod events
        - level: Request
          omitStages:
            - "RequestReceived"
          verbs: ["create", "delete", "update", "patch", "deletecollection"]
          resources:
            - group: "" # core
              resources: ["pods"]
        {{ end }}
        # don't audit any kube-controller-manager events
        - level: None
          users: ["system:kube-controller-manager"]
        # Don't audit events from system users in kube-system
        - level: None
          userGroups: ["system:serviceaccounts:kube-system"]
        # Don't audit events from high traffic infrastructure components
        - level: None
          users: ["credentials-provider"]
        - level: None
          userGroups: ["system:nodes"]
          verbs: ["get"]
          resources:
            - group: "" # core
              resources: ["nodes", "nodes/status"]
        - level: None
          users:
            - system:kube-controller-manager
            - system:kube-scheduler
            - system:serviceaccount:kube-system:endpoint-controller
          verbs: ["get", "update"]
          namespaces: ["kube-system"]
          resources:
            - group: "" # core
              resources: ["endpoints"]
        - level: None
          users: ["system:apiserver"]
          verbs: ["get"]
          resources:
            - group: "" # core
              resources: ["namespaces", "namespaces/status", "namespaces/finalize"]
        # Don't log HPA fetching metrics.
        - level: None
          users:
            - system:kube-controller-manager
          verbs: ["get", "list"]
          resources:
            - group: "metrics.k8s.io"
        # Don't log these read-only URLs.
        - level: None
          nonResourceURLs:
            - /healthz*
            - /version
            - /swagger*
        # Don't log events requests.
        - level: None
          resources:
            - group: "" # core
              resources: ["events"]
        # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data,
        # so only log at the Metadata level.
        - level: Metadata
          resources:
            - group: "" # core
              resources: ["secrets", "configmaps"]
            - group: authentication.k8s.io
              resources: ["tokenreviews"]
          omitStages:
            - "RequestReceived"
{{ if and (eq .Cluster.ConfigItems.enable_default_sa "true") (eq .Cluster.ConfigItems.auditlog_read_access "true") }}
        - level: None
          verbs: ["watch", "list", "get"]
          userGroups: ["system:serviceaccounts:kube-system"]
        - level: Request
          verbs: ["watch", "list", "get"]
          userGroups: ["system:serviceaccounts"]
          omitStages:
          - "RequestReceived"
{{ end }}
        # Don't audit read-only events.
        - level: None
          verbs: ["watch", "list", "get"]
        # Default level for all other requests.
        - level: Request
          omitStages:
            - "RequestReceived"

{{ if and (eq .Cluster.ConfigItems.enable_default_sa "true") (eq .Cluster.ConfigItems.auditlog_read_access "true") }}
  - owner: root:root
    path: /etc/kubernetes/config/audit-policy-ro.yaml
    content: |
      apiVersion: audit.k8s.io/v1beta1
      kind: Policy
      rules:
      - level: None
        userGroups: ["system:serviceaccounts:kube-system"]
      - level: Request
        verbs: ["watch", "list", "get"]
        userGroups: ["system:serviceaccounts"]
        omitStages:
        - "RequestReceived"
{{ end }}

  - owner: root:root
    path: /etc/kubernetes/config/encryption-config.yaml
    permissions: '0400'
    content: |
      apiVersion: apiserver.config.k8s.io/v1
      kind: EncryptionConfiguration
      resources:
        - resources:
          - secrets
          providers:
      {{- if ne .Cluster.ConfigItems.enable_encryption "true" }}
          - identity: {}
      {{- end }}
          - kms:
              name: aws-encryption-provider
              endpoint: unix:///var/run/kmsplugin/socket.sock
              cachesize: 50000
              timeout: 3s
      {{- if eq .Cluster.ConfigItems.enable_encryption "true" }}
          - identity: {}
      {{- end }}

# container linux config
passwd:
  users:
  - name: core
    ssh_authorized_keys:
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAt8djQXfn5U7H85oDzuZRfRONF+jVqn3Mp9t3tnBrJdKyTccfDovq1sekzEdOFdmj74yfS8bzaIO9pDUczy6j5k2MtDCoRnzAO6KZc46jMJ2GjhLArUuHLjmAw2r9LotZ30LEIEvJdmUI7mDlPMczv381PghyM8+DsYv62UrfjDiOsZ4EVkYnztQlO3ntNE16RFNj4fbfErQz67kmw0lB8C6bAf0RuRmvXzB7xRMplmknQnLusoURmySKdZM0GUe0VY6fmqOsgzHVLoEs1m82V8QK1ac/1DSHA91v50MbpCjTVLaRhjR8nmhWBedlhb6j5ClZdAQ8iwyyWC1MFQuvKw== henning@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCs4NhH7uwlnklYYlV1GP57XX9NHYgXNv0njfEVowR1jFSKiMdEUtPKz5lOAeDtKpck9HyjxVOTSutNOIBZkkgN/FgkcpNbc59nIO4ELUzipkJivuYNO1lDAjCQi1qwYo+uksiNfcsao9mn7nd9Rh1g8TXYv95TSvml9v/Dolmanm1qj6OkbDw1xIurnNsoCjdxCWwSRGNja4r+PQc8pi+1xpdUBEvn40CeBdU7b/hZnv/BM9FIKSsVlIwMR2i/Co2rxCKo9B3q4dmdQ/2C1QczINVpPQcNUMuiljJFMXvT7dgfNsnUBe8vFuoPgqohJ/m8AiKZZOyoRNiCuELnKLRKqxosDmJz47Y0YiYgZk9jpnmt+x1fwqhY2R85F7W4RybpX3AFL1jOqOT2lE+idkhyeFq/pPoAiPvUcpQSmL9AwlrG6cPklTJZW+dUzH/W6kNlgl/T6hnMn4Mu+IljG08Iyb/HBdmOX+uRq5wdF8lI9Zjzlwg+j7HMa3p1O7MNwpSJVjVXkhUXH0WrFrK2JkwgXokIWvu0o+lajYOmXRQeGCyVybg06WFCzOXnK2toVucFMuAGoM0NkthAnodZCk+xXLNrtHOYagpdJ/x/Q88vuDsZr7IG0NvgX/OCq1a5lpnIydCe+tABNNKcRaOuOLbDYVgUaeVzIXyJjRYu5ZN/JQ== mikkel.larsen@zalando.de'
    - 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIISHc8p8+ycB9H6SI/i3Uu/OI5G3vYNsZTn0DffPvfOA martin.linkhorst@zalando.de'
    - 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIFVmr+Y3hBvnz2xgSWoaxaPxnExcEXOghUozupU9bKNR nick@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCq3oEP8qhMvGtlR1bgVc9tFOVJ5B5RMKtm6UQ/zXQUpm8DQ04SxdM2U7TfuLien2HSfpHAlYe0eLJZUfIqCXUeZ37v0ozj2RglireEcJm0t9XJ7kTS4kqVxrL6iuN6qQVGHs0vxoo/o9+SP0YkuuJoXwJvVI4yKVbnbfA5hKaAffAYPmfgqOZ7+3AMwmaj/D3tI0xVEA48ptGkj5nnOl0pXlfLRNvbnXOCa/dTKUgkma1F0lXoTipkRspsMEiAnwfJ1dwnzgNzllt//Ao/H+yOVR8fWJ7d+nowszIk6zwUR7c6walxKKf5Oy5bQBU49MZ6xLP1oma9F2+llmV7qpqx rodrigo.reis@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCqAikaHsZWMuJvKZphZPZG0fnKMvVCRfBAbIS6e0Y+YqM0PfsWgB5e4f5TrbisQHdKopbfZVwYIaV/NegEuinrYPKC7t2ese/HjxgjHR95zHOcDP19Cbo+xeyH8zbRd9K3iRSyCUSMNRw5NL6zN8JOSl12m8QWQA4hTjFTmt870fIT4RLxu9qGlbQipUm57E/SotsNC41MQ/PsLQzOAviKrkS1rei2vzRHzAcjz1Z7GT5oH+dFVUC66kKa0XWDvq+VtkRVoLvS2chrIPCgESeeZAyOKyiOoyJxFFFiMVK48MWDBBIYTIsHE0qs/RwBi9+8lQGiHK5Rpk2djcloO0c7 sandor.szuecs@zalando.de'
    - 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINkh52Py+FvH9CRLDQg0gzvjEIrzwA45yMTXTsl2BVxV alexey.ermakov@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDakbukcXXmMyyxw5h3J8h41FK8b8/qjiX/u4BP+qQpQ3x/1VkppIpzHwLcjVThNspwOKKU6QwcaLKpJ+g3mYWdilsl7eFT5hAiIXq4OLe9XynXp1ZEduqKk7tgvjClo7OzuSdEfKtWkD35hzXWigVfJFZhSN9bLdiEzuIEHf0jEo2mUXADgAzSwbaTcVUreH/IR6SAYBVh4XgKoQjOmWrizJguYNk+DgBW6/R+5JQi8YYPSuevbcEKXXm1ZfOudNv2ebOL1rA4I+VDe2xW+JVwKIvAN3odt0zOH2NFr1kFU1GTVyD2ZYtyTNNae9a+mQ2Ltw5pzKjA4zjFctQrrI+yPEIcf64mccumIoRMjWozPB801VbZqUVyG0XhzHW7RNmTmmLsNa/STtYI9Xaqfrz2n3PgpYJ/bB42l4Ez9Oblh9rZU0aisr6risLh5XXgCa9NezMjTczMHJE0jVINgeIMsCleNF0HrkF26Uo1MJO1pOMZOGZzXSksB79TmTwjRdvQT/uvSAElBrthmRgj82pDsRdNoipp6VMx54m2KbvRyq79PVZP69NGWdAhJBw1SV0447kT1tuoqDTUskS4es1GoSu5sqtW4eF4Q6oju8+01l3ygLKmPPTbFVRcs6bBvHjnB3RYwgai5z0U16rsh7LKUwhYsRiar3lmrhVvoc95sw== muhammad.muaaz.saleem@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQD7rIzckgwfYqM7dvF4nxMh7f8IQ2ydAPX9dq1EbXEL5HpcdSBstXGyUxPpdTHnFxPJH2KTtkLGbvIISEQJoVonK2QdtgGQWwSNDxquLaaFgDJLO9vF2I3QVeO7U9c8sRHjBnpxHExsadsWGcNgRf34KfNAMA/94cEKk7cXZzCBiFdD5TXHmN5SfHlU/Yv7Rw16dT3MXkHAtCPWTYn8eongopygur5v9rOX+0Ntku6sJM5ZxvfVBdLl053vUfmfhLskZ1OSMFMphXpsoaavR3JCf285orONs173bAedmU8YrIjNmZgaik5oT7ITX2zn/cy2I2ZzM6ITjvcwb512+ideGkbWQgiGLSXm94OxPPjXTy+ugGoPY1WBdri1SRoRaaCNF2oJlIcecBJr69eDE3UmJta+bsKZkLyd+6sWZ9xYMRJOtbK1ABNEIowEz1djqMDIQFHRjQcgeZ8N2Zi3cDm71q1TXyLzTwZ2knH0GSwP6lNZaf2jJxMUq/Df9J9M/Keeujp5vQul6PyM/k9/5mWjWGe1aDcMBcx1icV5eyeFyQS36gh066RveIPmcs88aNomf/XdFTbHgWvNq83GienPRhdmeL/Vo46hgtBB7k6SQzR2JA3hpn3rKkVdGSWLRUXSMJO9JnLjpNo6uDwC8Zdnqwcq9SDk2tUBf3gJdnRGEw== arjun.naik@zalando.de'
    - 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDE5iWU/7Y9Frq15Q3JyU/wuU/h5kNPhx68FWHPLK4yeCEDTd/7y3o6UQ9xRPF5LNJN/ly9KTPIIO7CQ92grj7vALs2loCyhdh4LjuopqmccaRM5h7AUDmNMeyd8FEWPraal+OyIyvoPIZ+DcsojXZj57e8cvcIRqleqzvDgAfAHbKJrtTMkysXPTUOcsInFADqU4hLY4vS9xmbfVuOajH7RvapIIE6TOxDXKcww2DibFx5LhcO/b/WaeQ0qw1FGbyn7GEXPYBaS8rM+xGTMw3oSxjnWX3Yrq8J4b0RgD5fx0eDE284BMPB8JrZQC3JzZroOPml2uqFdGycWq/Anx8+qmumtjKiEMx/NwA9b3q5frnjLy96tJrAZYzGQ9FZA6/cHeXnapti7j0Vsy4nI8AJMTkXdWlTMIJILl0Jeo1bfabZkv0j1CxL3sHQIxs8MA0NTeCXM196mWXhxueCnq/0G8ivJv+iTVo1mnxw2onBneYgYw+X6cyg0pIK2czABe5tgpgqfnBMpBBQbVOa7DtUcZncfDIZB2VU+GbQKW9fUcfbkkCzaCxHH39aKZ+tCOutQ5MwF0Rap+HDDnsy5IgQ56XwhgQdyiK+E/kdhIpDq6wkdvQO1HONyC1L8WvMy7EVpJkK8UxIJkQQtqPDZ7V0TbyzpvrjL2EnWFIzghqrdQ== dion.bramley@zalando.de'
systemd:
  units:
  # disable automatic updates
  - name: update-engine.service
    mask: true
  - name: locksmithd.service
    mask: true

{{if .Values.instance_info.NVMEInstanceStorage }}
  - name: {{if index .NodePool.ConfigItems "instance_storage_mount_path"}}{{.NodePool.ConfigItems.instance_storage_mount_path | mountUnitName}}{{else}}var-lib-docker{{end}}.mount
    enable: true
    contents: |
      [Unit]
      Before=local-fs.target

      [Mount]
      What=/dev/nvme0n1
      Where={{if index .NodePool.ConfigItems "instance_storage_mount_path"}}{{.NodePool.ConfigItems.instance_storage_mount_path}}{{else}}/var/lib/docker{{end}}
      Type=ext4

      [Install]
      WantedBy=local-fs.target
{{end}}

  - name: set-hostname.service
    enable: true
    contents: |
      [Unit]
      Wants=network.target
      Before=docker.service

      [Service]
      Type=simple
      Restart=on-failure
      RestartSec=1
      ExecStart=/usr/bin/bash -c "/usr/bin/hostnamectl set-hostname $(/usr/bin/curl --silent --fail http://169.254.169.254/latest/meta-data/local-hostname)"

      [Install]
      WantedBy=multi-user.target

  - name: docker.service
    dropins:
    - name: 40-flannel.conf
      contents: |
        [Service]
        EnvironmentFile=/etc/kubernetes/cni/docker_opts_cni.env
    - name: 60-dockeropts.conf
      contents: |
        [Service]
        Environment="DOCKER_OPTS=--log-opt=max-file=2 --log-opt=max-size=50m"
        Environment=DOCKER_SELINUX=

  - name: meta-data-iptables.service
    enable: true
    contents: |
      [Unit]
      After=private-ipv4.service

      [Service]
      Type=simple
      Restart=on-failure
      RestartSec=1
      ExecStart=/opt/bin/meta-data-iptables.sh

      [Install]
      WantedBy=multi-user.target

  - name: dockercfg.service
    enable: true
    contents: |
      [Unit]
      After=network.target

      [Service]
      Type=simple
      Restart=on-failure
      RestartSec=5
      ExecStartPre=/usr/bin/mkdir -p /root/.docker
      ExecStart=/opt/bin/dockercfg.sh

      [Install]
      WantedBy=multi-user.target

  - name: timesyncd-enable-network-time.service
    enable: true
    contents: |
      [Service]
      Type=oneshot
      ExecStart=/usr/bin/timedatectl set-ntp true

      [Install]
      WantedBy=multi-user.target

  - name: private-ipv4.service
    enable: true
    contents: |
      [Unit]
      After=network.target
      Description=Set PRIVATE_EC2_IPV4 env

      [Service]
      ExecStart=/usr/bin/bash -c "/usr/bin/systemctl set-environment PRIVATE_EC2_IPV4=$(/usr/bin/curl --silent --fail http://169.254.169.254/latest/meta-data/local-ipv4)"
      RemainAfterExit=yes

      [Install]
      WantedBy=multi-user.target

  - name: kubelet.service
    enable: true
    contents: |
      [Unit]
      After=docker.service dockercfg.service meta-data-iptables.service private-ipv4.service

      [Service]
      Environment=KUBELET_IMAGE_TAG=v1.11.3
      Environment=KUBELET_IMAGE_URL=docker://registry.opensource.zalan.do/teapot/hyperkube
      Environment="RKT_RUN_ARGS=--insecure-options=image \
      --uuid-file-save=/var/run/kubelet-pod.uuid \
      --volume dns,kind=host,source=/etc/resolv.conf \
      --mount volume=dns,target=/etc/resolv.conf \
      --volume hosts,kind=host,source=/etc/hosts \
      --mount volume=hosts,target=/etc/hosts \
      --volume var-log,kind=host,source=/var/log \
      --mount volume=var-log,target=/var/log \
      --volume var-lib-cni,kind=host,source=/var/lib/cni \
      --mount volume=var-lib-cni,target=/var/lib/cni \
      --volume data,kind=host,source=/data \
      --mount volume=data,target=/data \
      --volume dockercfg,kind=host,source=/root/.docker/config.json \
      --mount volume=dockercfg,target=/root/.docker/config.json \
      --set-env=HOME=/root"
      ExecStartPre=/usr/bin/mkdir -p /var/log/containers
      ExecStartPre=/bin/mkdir -p /var/lib/cni
      ExecStartPre=/bin/mkdir -p /data
      ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
      ExecStart=/usr/lib/coreos/kubelet-wrapper \
      --cni-conf-dir=/etc/kubernetes/cni/net.d \
      --network-plugin=cni \
      --container-runtime=docker \
      --cadvisor-port=4194 \
      --register-with-taints={{if index .NodePool.ConfigItems "taints"}}{{.NodePool.ConfigItems.taints}}{{end}} \
      --register-node \
      --node-labels=kubernetes.io/role=worker \
      --node-labels=kubernetes.io/node-pool={{ .NodePool.Name }}{{if index .NodePool.ConfigItems "labels"}},{{.NodePool.ConfigItems.labels}}{{end}} \
      --node-labels=aws.amazon.com/spot={{if ne .Values.spot_price ""}}true{{else}}false{{end}} \
      --node-labels={{ .Values.node_labels }} \
      --cluster-dns=${PRIVATE_EC2_IPV4},10.3.0.11 \
      --cluster-domain=cluster.local \
      --kubeconfig=/etc/kubernetes/kubeconfig \
      --healthz-bind-address=0.0.0.0 \
      --healthz-port=10248 \
      --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
      --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem \
      --cloud-provider=aws \
      --feature-gates=ExperimentalCriticalPodAnnotation=true,TaintBasedEvictions=true \
      --pod-infra-container-image=registry.opensource.zalan.do/teapot/pause-amd64:3.1 \
{{- if not (index .Cluster.ConfigItems "enable_cfs_quota") }}
      --cpu-cfs-quota=false \
{{- end }}
      --system-reserved=cpu=100m,memory=164Mi \
      --kube-reserved=cpu=100m,memory=282Mi
      ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
      Restart=always
      RestartSec=10

      [Install]
      WantedBy=multi-user.target

  - name: kube-node-drainer.service
    enable: true
    contents: |
      [Unit]
      Description=drain this k8s node to make running pods time to gracefully shut down before stopping kubelet
      After=docker.service kubelet.service

      [Service]
      Type=oneshot
      RemainAfterExit=true
      ExecStart=/bin/true
      TimeoutStopSec=120s
      ExecStop=/opt/bin/drain-node

      [Install]
      WantedBy=multi-user.target

{{if eq .NodePool.DiscountStrategy "spot_max_price"}}
  - name: spot-termination-handler.service
    enable: true
    contents: |
      [Unit]
      Description=poll for AWS Spot termination signal and force node shutdown
      After=network.target

      [Service]
      Type=simple
      Restart=on-failure
      RestartSec=5
      ExecStart=/usr/bin/rkt run --insecure-options=image \
        --volume dns,kind=host,source=/run/systemd/resolve/resolv.conf,readOnly=true \
        --mount volume=dns,target=/etc/resolv.conf \
        --net=host \
        docker://registry.opensource.zalan.do/teapot/spot-termination-handler:master-1
      ExecStopPost=-/opt/bin/spot-shutdown

      [Install]
      WantedBy=multi-user.target
{{end}}

storage:
  files:
  - filesystem: root
    path: /etc/kubernetes/kubeconfig
    mode: 0644
    contents:
      inline: |
        apiVersion: v1
        kind: Config
        clusters:
        - name: local
          cluster:
            server: {{ .Cluster.APIServerURL }}
        users:
        - name: kubelet
          user:
            token: {{ .Cluster.ConfigItems.worker_shared_secret }}
        contexts:
        - context:
            cluster: local
            user: kubelet
          name: kubelet-context
        current-context: kubelet-context

  - filesystem: root
    path: /etc/kubernetes/cni/docker_opts_cni.env
    mode: 0644
    contents:
      inline: |
        DOCKER_OPT_BIP=""
        DOCKER_OPT_IPMASQ=""

  - filesystem: root
    path: /etc/kubernetes/ssl/worker.pem
    mode: 0664
    contents:
      remote:
        url: "data:text/plain;base64,{{ .Cluster.ConfigItems.worker_cert_decompressed }}"

  - filesystem: root
    path: /etc/kubernetes/ssl/worker-key.pem
    mode: 0664
    contents:
      remote:
        url: "data:text/plain;base64,{{ .Cluster.ConfigItems.worker_key_decompressed }}"

  - filesystem: root
    path: /etc/kubernetes/ssl/ca.pem
    mode: 0664
    contents:
      remote:
        url: "data:text/plain;base64,{{ .Cluster.ConfigItems.ca_cert_decompressed }}"

  - filesystem: root
    path: /opt/bin/dockercfg.sh
    mode: 0755
    contents:
      inline: |
        #!/bin/bash
        set -euo pipefail

        iid="instance-identity-document:$(curl --silent --fail http://169.254.169.254/latest/dynamic/instance-identity/pkcs7)"
        iid="$(echo -n "$iid" | base64 -w 0)"
        cat << EOF > /root/.docker/config.json
        {
          "auths": {
            "https://pierone.stups.zalan.do": {
              "auth": "${iid}"
            }
          }
        }
        EOF

  - filesystem: root
    path: /opt/bin/meta-data-iptables.sh
    mode: 0755
    contents:
      inline: |
        #!/bin/bash
        set -euo pipefail

        /usr/sbin/iptables \
          --append PREROUTING \
          --protocol tcp \
          --destination 169.254.169.254 \
          --dport 80 \
          --in-interface cni0 \
          --match tcp \
          --jump DNAT \
          --table nat \
          --to-destination ${PRIVATE_EC2_IPV4}:8181

  {{if index .Cluster.ConfigItems "docker-1.12"}}
  - filesystem: root
    path: /etc/coreos/docker-1.12
    mode: 0644
    contents:
      inline: yes
  {{end}}

  - filesystem: root
    path: /home/core/.toolboxrc
    mode: 0644
    contents:
      inline: |
        TOOLBOX_DOCKER_IMAGE=registry.opensource.zalan.do/teapot/microscope
        TOOLBOX_DOCKER_TAG=v0.0.4

  - filesystem: root
    path: /root/.toolboxrc
    mode: 0644
    contents:
      inline: |
        TOOLBOX_DOCKER_IMAGE=registry.opensource.zalan.do/teapot/microscope
        TOOLBOX_DOCKER_TAG=v0.0.4

  - filesystem: root
    path: /etc/systemd/timesyncd.conf
    mode: 0644
    contents:
      inline: |
        [Time]
        NTP=169.254.169.123

  - filesystem: root
    path: /opt/bin/drain-node
    mode: 0755
    contents:
      inline: |
        #!/bin/bash
        set -euo pipefail

        /usr/bin/rkt run --insecure-options=image \
          --volume=kube,kind=host,source=/etc/kubernetes,readOnly=true \
          --mount=volume=kube,target=/etc/kubernetes \
          --volume dns,kind=host,source=/run/systemd/resolve/resolv.conf,readOnly=true \
          --mount volume=dns,target=/etc/resolv.conf \
          --net=host \
          docker://registry.opensource.zalan.do/teapot/hyperkube:v1.11.3 \
          --exec=/kubectl -- \
          --kubeconfig=/etc/kubernetes/kubeconfig \
          label node "$(hostname)" \
          lifecycle-status=draining \
          --overwrite

        /usr/bin/rkt run --insecure-options=image \
          --volume=kube,kind=host,source=/etc/kubernetes,readOnly=true \
          --mount=volume=kube,target=/etc/kubernetes \
          --net=host \
          --volume dns,kind=host,source=/run/systemd/resolve/resolv.conf,readOnly=true \
          --mount volume=dns,target=/etc/resolv.conf \
          docker://registry.opensource.zalan.do/teapot/hyperkube:v1.11.3 \
          --exec=/kubectl -- \
          --kubeconfig=/etc/kubernetes/kubeconfig \
          drain "$(hostname)" \
          --ignore-daemonsets \
          --delete-local-data \
          --force

{{if eq .NodePool.DiscountStrategy "spot_max_price"}}
  - filesystem: root
    path: /opt/bin/spot-shutdown
    mode: 0755
    contents:
      inline: |
        #!/bin/bash
        set -euo pipefail

        if [[ $EXIT_CODE -ne 0 ]]; then
          shutdown now
        fi
{{end}}

{{if .Values.instance_info.NVMEInstanceStorage }}
  filesystems:
  - name: instance-storage
    mount:
      device: /dev/nvme0n1
      format: ext4
      wipe_filesystem: true
{{end}}
